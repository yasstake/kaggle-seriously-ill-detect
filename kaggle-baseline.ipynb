{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/yasstake/kaggle-baseline?scriptVersionId=124130768\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# 趣旨\n\nはじめてなのに思いつくままに始めてみたら、時間を大量に消費して行き詰ってしまった。体系的なアプローチが必要そうだ。\n\nそこで「Kaggleで磨く機械学習の実践力（諸橋政幸　著）」のステップに従いやってみることにした。この本はTitanicを例にStepByStepでやり方を書いてあるハンズオン形式の本。ちょうど今回の例もTitanicと同じ２値問題なので応用できそう。\n\n本の章毎にStepByStepで今回の課題をやってみる(具体的には４章から始まる)\n\n著作権の問題もあるので章の名前をのみを引用しています。\nそのため全体の考え方などは本をみないとわからないかもしれません。この本、初心者の私にとってはとてもわかりやすかったです。ぜひ、章番号とあわせて読んでみることおすすめ。","metadata":{}},{"cell_type":"markdown","source":"# 4 ベースラインの作成\n\n* lightgbmとk-fold法を用いたシンプルなベースラインを作成する\n* 特徴量エンジニアリングは最初はやらない。\n  * 数値データは全部利用する。\n  * 文字列データは一旦削除する（ベースライン完了後の特徴量エンジニアリングで実施する[予定]）\n\n## 4.2分析設計\n\n課題が何であるかを明確にする。\n* 目的変数: カラム['target_label']の値\n* 目的変数の特徴:「1＝重症」、「0＝重症ではない」の２値\n* 評価指標: AUC(Area Under the Curve)","metadata":{}},{"cell_type":"markdown","source":"## 4.3 ファイルの読み込み\n\n* 最初に必要ライブラリをインポートする\n* 次にデータファイルを読み込む。データファイルは以下の２つ\n  * `test_df.csv` テスト（提出用）データ\n  * `train_df.csv`　訓練用データ","metadata":{}},{"cell_type":"code","source":"! pip install numpy\n! pip install sklearn\n! pip install pandas\n! pip install matplotlib\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:30:20.611142Z","iopub.execute_input":"2023-03-31T17:30:20.611719Z","iopub.status.idle":"2023-03-31T17:31:06.249669Z","shell.execute_reply.started":"2023-03-31T17:30:20.611676Z","shell.execute_reply":"2023-03-31T17:31:06.248192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 必要ファイルの読み込み\nimport numpy as np\nfrom sklearn.model_selection import StratifiedKFold\nimport pandas as pd\nimport matplotlib.pyplot as plt\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:31:06.252326Z","iopub.execute_input":"2023-03-31T17:31:06.252734Z","iopub.status.idle":"2023-03-31T17:31:06.259087Z","shell.execute_reply.started":"2023-03-31T17:31:06.252694Z","shell.execute_reply":"2023-03-31T17:31:06.257887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# データの読み込み\n\n# for local\n#DATA_DIR = './input/'\n\n# for kaggle notebook\nDATA_DIR = '/kaggle/input/prediction-of-seriously-ill-patients/'\n\ntest_df = pd.read_csv(DATA_DIR + 'test_df.csv')\ntrain_df = pd.read_csv(DATA_DIR + 'train_df.csv')\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:31:06.260714Z","iopub.execute_input":"2023-03-31T17:31:06.261166Z","iopub.status.idle":"2023-03-31T17:31:07.427439Z","shell.execute_reply.started":"2023-03-31T17:31:06.261119Z","shell.execute_reply":"2023-03-31T17:31:07.42617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.4 データの確認（簡易）","metadata":{}},{"cell_type":"code","source":"# レコード数とカラム数の確認\n\nprint('train_df.shape: ', train_df.shape)\nprint('test_df.shape: ', test_df.shape)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:31:07.430827Z","iopub.execute_input":"2023-03-31T17:31:07.432311Z","iopub.status.idle":"2023-03-31T17:31:07.44065Z","shell.execute_reply.started":"2023-03-31T17:31:07.432252Z","shell.execute_reply":"2023-03-31T17:31:07.43878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.4.2 カラムごとのデータの種類の確認","metadata":{}},{"cell_type":"code","source":"# show first 5 rows\npd.set_option('display.max_columns', 100)\npd.set_option('display.max_rows', 100)\nprint(train_df.head())","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:31:07.441988Z","iopub.execute_input":"2023-03-31T17:31:07.442336Z","iopub.status.idle":"2023-03-31T17:31:07.503054Z","shell.execute_reply.started":"2023-03-31T17:31:07.442303Z","shell.execute_reply":"2023-03-31T17:31:07.501795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# show each data types and non null count\nprint(train_df.info())","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:31:07.505005Z","iopub.execute_input":"2023-03-31T17:31:07.505867Z","iopub.status.idle":"2023-03-31T17:31:07.563583Z","shell.execute_reply.started":"2023-03-31T17:31:07.505818Z","shell.execute_reply":"2023-03-31T17:31:07.562248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_object_column_name(df):\n    '''\n    returns object columns in dataframe\n    '''\n    return df.select_dtypes(include=['object']).columns\n\ndef strip_object_columns(df):\n    '''\n    drop columns which has object type\n    '''\n    return df.select_dtypes(exclude=['object'])\n    \n\n\nprint('train_df object columns: ', get_object_column_name(train_df))\nprint('train_df not object columns: ', strip_object_columns(train_df).columns)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:31:07.565521Z","iopub.execute_input":"2023-03-31T17:31:07.566398Z","iopub.status.idle":"2023-03-31T17:31:07.594723Z","shell.execute_reply.started":"2023-03-31T17:31:07.566347Z","shell.execute_reply":"2023-03-31T17:31:07.593362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 4.4.3 欠損値の確認","metadata":{}},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:31:07.59625Z","iopub.execute_input":"2023-03-31T17:31:07.596935Z","iopub.status.idle":"2023-03-31T17:31:07.635837Z","shell.execute_reply.started":"2023-03-31T17:31:07.596898Z","shell.execute_reply":"2023-03-31T17:31:07.634557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.5 データセットの作成","metadata":{}},{"cell_type":"code","source":"x_train, y_train, id_train = train_df.drop(['id', 'target_label'], axis=1), train_df['target_label'], train_df['id']\nx_test, id_test = test_df.drop(['id'], axis=1), test_df['id']","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:31:07.637503Z","iopub.execute_input":"2023-03-31T17:31:07.638223Z","iopub.status.idle":"2023-03-31T17:31:07.65983Z","shell.execute_reply.started":"2023-03-31T17:31:07.638174Z","shell.execute_reply":"2023-03-31T17:31:07.658627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"x_train:{} | y_train: {} | id_train: {}\".format(x_train.shape, y_train.shape, id_train.shape))\nprint(\"x_test:{} | id_test: {}\".format(x_test.shape, id_test.shape))","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:31:07.663663Z","iopub.execute_input":"2023-03-31T17:31:07.664022Z","iopub.status.idle":"2023-03-31T17:31:07.67091Z","shell.execute_reply.started":"2023-03-31T17:31:07.663986Z","shell.execute_reply":"2023-03-31T17:31:07.669612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4.6 バリデーション設計\n\n## 4.6.2 ホールドアウト検証と交差検証\n\nクロスバリデーション（交差検証）を採用して実装してみる。\n\n```\n`StratifiedKFold`は、クラスの分布がバランスよくなるように、データを分割する交差検証手法の一種です。具体的には、データセットをk個のサブセットに分割し、各サブセットがクラスの比率を保ったままランダムに抽出されるようにします。これにより、モデルの性能を評価するためのデータが、すべてのクラスにわたって均等に分散することが保証されます。\n```\n\nhttps://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n\n*Params*\n * `n_splits` 分割数\n * `shuffle` バッチ毎にシャッフルするか？（default False)\n * `random_state` クラス毎のシャッフル設定　https://scikit-learn.org/stable/modules/cross_validation.html#stratified-k-fold\n ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\ndef get_fold(n_splits=5, random_state=1):\n    return StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state).split(x_train, y_train)\n\n\n# データがバランスしているか確認（数・割合）\nfor i_fold, (train_index, validate_index) in enumerate(get_fold()):\n    xf_train, xf_validate = x_train.iloc[train_index], x_train.iloc[validate_index]\n    yf_train, yf_validate = y_train.iloc[train_index], y_train.iloc[validate_index]\n    \n    print('#{}| xf_train: {} | yf_train: {} (serious: {}) | xf_validate: {} | yf_validate: {} (serious: {})'\n          .format(i_fold, xf_train.shape, yf_train.shape, yf_train.mean(),\n                  xf_validate.shape, yf_validate.shape, yf_validate.mean())\n    )\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:31:07.672762Z","iopub.execute_input":"2023-03-31T17:31:07.673091Z","iopub.status.idle":"2023-03-31T17:31:07.803463Z","shell.execute_reply.started":"2023-03-31T17:31:07.673059Z","shell.execute_reply":"2023-03-31T17:31:07.802308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_fixed = {\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'learning_rate': 0.01,\n    'num_leaves': 2**5,\n    'n_estimators': 10000,\n    'random_state': 1,\n    'importance_type': 'gain',\n}\n\ndef train_lgbt(x_train, y_train, x_validate, y_validate, param_fixed):\n    import lightgbm as lgb\n    from sklearn.metrics import roc_auc_score\n    from lightgbm import early_stopping\n    \n    param = param_fixed.copy()\n    \n    model = lgb.LGBMClassifier(**param)\n    model.fit(strip_object_columns(x_train), y_train, eval_set=[(strip_object_columns(x_validate), y_validate)], callbacks=[early_stopping(100, verbose=False)])\n    y_pred = model.predict_proba(strip_object_columns(x_validate))[:, 1]\n    auc = roc_auc_score(y_validate, y_pred)\n    \n    return model, auc\n\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:31:07.80458Z","iopub.execute_input":"2023-03-31T17:31:07.804886Z","iopub.status.idle":"2023-03-31T17:31:07.813917Z","shell.execute_reply.started":"2023-03-31T17:31:07.804855Z","shell.execute_reply":"2023-03-31T17:31:07.812663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# execute cross validation\n\ndef train_fold():\n    aucs = []\n    models = []\n\n    for i_fold, (train_index, validate_index) in enumerate(get_fold()):\n        xf_train, xf_validate = x_train.iloc[train_index], x_train.iloc[validate_index]\n        yf_train, yf_validate = y_train.iloc[train_index], y_train.iloc[validate_index]\n    \n        model, auc_validate = train_lgbt(xf_train, yf_train, xf_validate, yf_validate, param_fixed)\n    \n        print('\\tFold#{}  AUC validate: {}'.format(i_fold, auc_validate))\n        \n        aucs.append(auc_validate)\n        models.append(model)\n        \n    return np.array(aucs), models\n\naucs, models = train_fold()","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:31:07.816044Z","iopub.execute_input":"2023-03-31T17:31:07.816519Z","iopub.status.idle":"2023-03-31T17:33:12.033073Z","shell.execute_reply.started":"2023-03-31T17:31:07.816471Z","shell.execute_reply":"2023-03-31T17:33:12.032139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.7.2 クロスバリデーションの場合\n\n説明変数の重要度の算出を行う。k個あるモデルにおける寄与度の平均をとる。","metadata":{}},{"cell_type":"code","source":"def display_importance(models):\n    importances = pd.DataFrame()\n    for i, model in enumerate(models):\n        importances['importance_{}'.format(i)] = model.feature_importances_\n    importances['importance'] = importances.mean(axis=1)\n    importances['feature'] = strip_object_columns(x_train).columns\n    importances = importances.sort_values('importance', ascending=False)\n    print(importances[['feature', 'importance']])\n    \nprint('AUC mean: {}'.format(aucs.mean()))\ndisplay_importance(models)","metadata":{"execution":{"iopub.status.busy":"2023-03-31T17:33:12.034664Z","iopub.execute_input":"2023-03-31T17:33:12.035304Z","iopub.status.idle":"2023-03-31T17:33:12.064182Z","shell.execute_reply.started":"2023-03-31T17:33:12.035249Z","shell.execute_reply":"2023-03-31T17:33:12.063341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4.8　モデル推論\n\nk-fold法では、２つの方法がとれるようだ。\n1. k-foldでトレーニングしたモデルk個のアンサンブルをとる。\n2. k-foldでは、特徴量・ハイパーパラメータの有効性の確認を行い、同じパラメータで全データでトレーニングする。\n\nここでは１の方法で一番簡単と思われる平均値をとって推論を行う。","metadata":{}},{"cell_type":"code","source":"def predict(models, x_test):\n    y_pred = np.zeros(len(x_test))\n    for model in models:\n        y_pred += model.predict_proba(strip_object_columns(x_test))[:, 1]\n    y_pred /= len(models)\n    return y_pred\n\npred = pd.DataFrame(predict(models, x_test), columns=['target_label'])\npred['id'] = id_test\n\n\ndef create_submission(df):\n    FILE_NAME='submission.csv'\n    df.to_csv(FILE_NAME, index=False, header=True)\n    print('Write complete to [{}]'.format(FILE_NAME))\n    \ncreate_submission(pred)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-31T23:26:28.023795Z","iopub.execute_input":"2023-03-31T23:26:28.024243Z","iopub.status.idle":"2023-03-31T23:26:28.11874Z","shell.execute_reply.started":"2023-03-31T23:26:28.024201Z","shell.execute_reply":"2023-03-31T23:26:28.117182Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_28/4050791309.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target_label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mid_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"],"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}